{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeH-qQlkw9PY",
    "outputId": "2670a13a-ea12-4e95-c3ca-d74ebfa31ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn==1.0 in /usr/local/lib/python3.7/dist-packages (1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imblearn\n",
    "!pip install scikit-learn==1.0 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VNEAq-VlbE6M"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.ensemble import (\n",
    "    BalancedBaggingClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-4zUudmPctIt",
    "outputId": "4c94068c-0a33-44fc-d3b9-17ec8960f71b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-72183c76-ec16-4ce5-9375-f6c37013f6dc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72183c76-ec16-4ce5-9375-f6c37013f6dc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-72183c76-ec16-4ce5-9375-f6c37013f6dc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-72183c76-ec16-4ce5-9375-f6c37013f6dc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "0     6  148  72  35    0  33.6  0.627  50  1\n",
       "1     1   85  66  29    0  26.6  0.351  31  0\n",
       "2     8  183  64   0    0  23.3  0.672  32  1\n",
       "3     1   89  66  23   94  28.1  0.167  21  0\n",
       "4     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "763  10  101  76  48  180  32.9  0.171  63  0\n",
       "764   2  122  70  27    0  36.8  0.340  27  0\n",
       "765   5  121  72  23  112  26.2  0.245  30  0\n",
       "766   1  126  60   0    0  30.1  0.349  47  1\n",
       "767   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
    "pima_dataframe = pd.read_csv(path, header=None)\n",
    "pima_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCa5IzaRcz_S",
    "outputId": "de0a7089-d909-4640-bf9a-6d60d7d9cf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_values = pima_dataframe.values\n",
    "pima_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61frapRec01e",
    "outputId": "a6c6e6d3-645d-49b9-dcfd-c9d33836743a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "u5w1NtHYc3dt"
   },
   "outputs": [],
   "source": [
    "pima_data, pima_labels = pima_values[:,:8],pima_values[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSaQ8_vQc5cd",
    "outputId": "6f5726a2-6dce-4ad6-9d1e-23ebf9001957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FunEpHNWc7bz",
    "outputId": "aae747e1-ccca-40f0-81a8-6c2beea9b243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data.shape, pima_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wqj_OqJc-gH",
    "outputId": "be7fc6a1-8e6f-4790-a41c-09fbff747b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_labels_classes = np.unique(pima_labels)\n",
    "pima_labels_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Hk3oEIcEdATH"
   },
   "outputs": [],
   "source": [
    "pima_number_classes = len(pima_labels_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzpuJGgNdCyW",
    "outputId": "b2d63e4a-2f22-467c-81bd-a7e20dec3a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_number_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvNhNls_dEl3",
    "outputId": "c5d6824b-3c41-4c09-e24d-511690127872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the number of class 0.0 is 500 and the ratio of this class is 65.10416666666666 to all data\n",
      " the number of class 1.0 is 268 and the ratio of this class is 34.89583333333333 to all data\n"
     ]
    }
   ],
   "source": [
    "for label in pima_labels_classes:\n",
    "    total = len(pima_labels[pima_labels==label])\n",
    "    ratio = (total / float(len(pima_labels))) * 100\n",
    "    print(f' the number of class {label} is {total} and the ratio of this class is {ratio} to all data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "on2yF5Z0dHma"
   },
   "outputs": [],
   "source": [
    "pima_dataframe_new =pima_dataframe.sort_values(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Mfti3PEqdOEh",
    "outputId": "f106046b-64b3-452b-cc5d-47623a6597f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6c7ab4cf-91a8-423c-9eab-d324170ea9dc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1.268</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>105</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.452</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.269</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>140</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.571</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>11</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.578</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>8</td>\n",
       "      <td>181</td>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>495</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.615</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c7ab4cf-91a8-423c-9eab-d324170ea9dc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6c7ab4cf-91a8-423c-9eab-d324170ea9dc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6c7ab4cf-91a8-423c-9eab-d324170ea9dc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "383   1   90  62  18   59  25.1  1.268  25  0\n",
       "465   0  124  56  13  105  21.8  0.452  21  0\n",
       "466   0   74  52  10   36  27.8  0.269  22  0\n",
       "467   0   97  64  36  100  36.8  0.600  25  0\n",
       "469   6  154  78  41  140  46.1  0.571  27  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "193  11  135   0   0    0  52.3  0.578  40  1\n",
       "485   0  135  68  42  250  42.3  0.365  24  1\n",
       "484   0  145   0   0    0  44.2  0.630  31  1\n",
       "186   8  181  68  36  495  30.1  0.615  60  1\n",
       "0     6  148  72  35    0  33.6  0.627  50  1\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_dataframe_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxqzQrP4dU9z"
   },
   "source": [
    "we want 10 percent of \"1\" label in all data we have 268 numbers of \"1\" that is 34.8 with cross multipling we find out we need 77 of \"1\" label 268-x=77 give us x equal to 191 but after applying this to data the percentage of \"1\" was 13.3 after i use try and error to find the appropriate number of \"1\" label and i find 56, 268-56=212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "xK66ctl_dY0n"
   },
   "outputs": [],
   "source": [
    "pima_dataframe_new_values =pima_dataframe_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LURAwyqGdgLn",
    "outputId": "f5338107-ab31-4ed7-cabc-5aa929952bf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_dataframe_new_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "yTX6ABoJdjME"
   },
   "outputs": [],
   "source": [
    "pima_values_adjusted = pima_dataframe_new_values[:-212,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a-IVCjBdmNR",
    "outputId": "e06beb29-03b7-4867-fa11-da427994443a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_values_adjusted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "B4HDhhsLdrH1"
   },
   "outputs": [],
   "source": [
    "X, Y = pima_values_adjusted[:, :-1], pima_values_adjusted[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PRIVe1SHduJw"
   },
   "outputs": [],
   "source": [
    "n_rows = X.shape[0]\n",
    "n_cols = X.shape[1]\n",
    "classes = np.unique(Y)\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6DkaPDLd13-",
    "outputId": "10442082-329a-4ca5-e161-2ecc176febdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Examples: 556\n",
      "N Inputs: 8\n",
      "N Classes: 2\n",
      "Classes: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('N Examples: %d' % n_rows)\n",
    "print('N Inputs: %d' % n_cols)\n",
    "print('N Classes: %d' % n_classes)\n",
    "print('Classes: %s' % classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCouotchd2j9",
    "outputId": "5621e66f-86de-4ee0-ed76-fa71fbb4635d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Class 0.0: 500 (89.92806%)\n",
      " - Class 1.0: 56 (10.07194%)\n"
     ]
    }
   ],
   "source": [
    "for c in classes:\n",
    "    total = len(Y[Y == c])\n",
    "    ratio = (total / len(Y)) * 100\n",
    "    print(' - Class %s: %d (%.5f%%)' % (str(c), total, ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpslkWuId58N",
    "outputId": "d5a1c6c2-4fae-4ff6-94f9-f98893991264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.   ,  90.   ,  62.   , ...,  25.1  ,   1.268,  25.   ],\n",
       "        [  0.   , 124.   ,  56.   , ...,  21.8  ,   0.452,  21.   ],\n",
       "        [  0.   ,  74.   ,  52.   , ...,  27.8  ,   0.269,  22.   ],\n",
       "        ...,\n",
       "        [ 11.   , 136.   ,  84.   , ...,  28.3  ,   0.26 ,  42.   ],\n",
       "        [  2.   ,  93.   ,  64.   , ...,  38.   ,   0.674,  23.   ],\n",
       "        [  5.   ,  97.   ,  76.   , ...,  35.6  ,   0.378,  52.   ]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "6cgKcf68d-WR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU832lMpet1n"
   },
   "source": [
    "# **RESAMPLING METHODS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "neTq69pqfBh5"
   },
   "outputs": [],
   "source": [
    "resampling_dict = {\n",
    "    \n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=1375,\n",
    "        replacement=False,\n",
    "    ),\n",
    "\n",
    "    'smote': SMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=1375,\n",
    "        k_neighbors=5,\n",
    "        n_jobs=4,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "E8DU6mrlfJeK"
   },
   "outputs": [],
   "source": [
    "# ensemble methods (with or without resampling)\n",
    "\n",
    "ensemble_dict = {\n",
    "\n",
    "    # balanced random forests (bagging)\n",
    "    'balancedRF': BalancedRandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        criterion='gini',\n",
    "        max_depth=3,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=1375,\n",
    "    ),\n",
    "\n",
    "    # bagging of Logistic regression, no resampling\n",
    "    'bagging': BaggingClassifier(\n",
    "        base_estimator=LogisticRegression(random_state=2909),\n",
    "        n_estimators=20,\n",
    "        n_jobs=4,\n",
    "        random_state=1375,\n",
    "    ),\n",
    "\n",
    "    # bagging of Logistic regression, with resampling\n",
    "    'balancedbagging': BalancedBaggingClassifier(\n",
    "        base_estimator=LogisticRegression(random_state=1375),\n",
    "        n_estimators=20,\n",
    "        max_samples=1.0,  # The number of samples to draw from X to train each base estimator\n",
    "        max_features=1.0,  # The number of features to draw from X to train each base estimator\n",
    "        bootstrap=True,\n",
    "        bootstrap_features=False,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=1375,\n",
    "    ),\n",
    "\n",
    "    # boosting + undersampling\n",
    "    'rusboost': RUSBoostClassifier(\n",
    "        base_estimator=None,\n",
    "        n_estimators=20,\n",
    "        learning_rate=1.0,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=1375,\n",
    "    ),\n",
    "\n",
    "    # bagging + boosting + under-sammpling\n",
    "    'easyEnsemble': EasyEnsembleClassifier(\n",
    "        n_estimators=20,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=1375,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5OjgtIG8iGP9"
   },
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=20, random_state=1375, max_depth=2, n_jobs=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print(\n",
    "        'Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print(\n",
    "        'Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "    return roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "eVR6yMG1iNLZ"
   },
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the peadaormance\n",
    "\n",
    "def run_adaboost(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    ada = AdaBoostClassifier(n_estimators=20, random_state=1375)\n",
    "    \n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = ada.predict_proba(X_train)\n",
    "    print(\n",
    "        'AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = ada.predict_proba(X_test)\n",
    "    print(\n",
    "        'AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "    return roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "y0dxxn5wfsy5"
   },
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the peensembleormance\n",
    "\n",
    "def run_ensemble(ensemble, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    ensemble.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = ensemble.predict_proba(X_train)\n",
    "    print(\n",
    "        'ensembleBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = ensemble.predict_proba(X_test)\n",
    "    print(\n",
    "        'ensembleBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))\n",
    "\n",
    "    return roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1BN6uT4ViU5p"
   },
   "outputs": [],
   "source": [
    "  x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X,  \n",
    "    Y, \n",
    "    test_size=0.3,\n",
    "    random_state=1375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n10TFtE6jJy0",
    "outputId": "4397ed83-4b50-4883-fb29-f1d8ff49f095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((389, 8), (167, 8), (389,), (167,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIR0wbGXjO0e",
    "outputId": "0ed5f41c-05bc-41fd-cd3d-32a30b86fc3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8986729644624382\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8484340044742729\n",
      "\n",
      "Train set\n",
      "AdaBoost roc-auc: 0.9710601289548657\n",
      "Test set\n",
      "AdaBoost roc-auc: 0.6545488441461595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "# we set variables in the same scale\n",
    "scaler = MinMaxScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "    \n",
    "# train model and store result\n",
    "roc = run_randomForests(x_train, x_test, y_train, y_test)\n",
    "results_dict[\"Random Forest\"] = roc\n",
    "print()\n",
    "# train model and store result\n",
    "roc = run_adaboost(x_train, x_test, y_train, y_test)\n",
    "results_dict[\"adaboost\"] = roc\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ut77er_plkOT",
    "outputId": "a8988092-d624-40aa-acec-32448b050ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n",
      "Train set\n",
      "Random Forests roc-auc: 0.9307479224376731\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8523489932885906\n",
      "\n",
      "balancedRF\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9210526315789473\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8333333333333334\n",
      "\n",
      "bagging\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.8768930874194033\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8762117822520507\n",
      "\n",
      "balancedbagging\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.8661718398560504\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.877703206562267\n",
      "\n",
      "rusboost\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9286249812565602\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.7026472781506339\n",
      "\n",
      "easyEnsemble\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9661868346078872\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8288590604026845\n",
      "\n",
      "smote\n",
      "Train set\n",
      "Random Forests roc-auc: 0.92640481814271\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8558911260253542\n",
      "\n",
      "balancedRF\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9210526315789473\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8333333333333334\n",
      "\n",
      "bagging\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.8768930874194033\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8762117822520507\n",
      "\n",
      "balancedbagging\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.8661718398560504\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.877703206562267\n",
      "\n",
      "rusboost\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9286249812565602\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.7026472781506339\n",
      "\n",
      "easyEnsemble\n",
      "Train set\n",
      "ensembleBoost roc-auc: 0.9661868346078872\n",
      "Test set\n",
      "ensembleBoost roc-auc: 0.8288590604026845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sampler in resampling_dict.keys():\n",
    "        \n",
    "        print(sampler)\n",
    "        \n",
    "        # resample\n",
    "        x_resampled, y_resampled = resampling_dict[sampler].fit_resample(x_train, y_train)\n",
    "        \n",
    "        # train model and store result\n",
    "        roc = run_randomForests(x_resampled, x_test, y_resampled, y_test)\n",
    "        results_dict[sampler] = roc\n",
    "        print()\n",
    "    \n",
    "        for ensemble in ensemble_dict.keys():\n",
    "        \n",
    "          print(ensemble)\n",
    "          \n",
    "          # train model and store result\n",
    "          roc = run_ensemble(ensemble_dict[ensemble], x_train, x_test, y_train, y_test)\n",
    "          results_dict[ensemble] = roc\n",
    "          print()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKZcegVWyY-5",
    "outputId": "1ce01ea4-58a5-425c-a81a-49ae5ad2f752"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.8484340044742729,\n",
       " 'adaboost': 0.6545488441461595,\n",
       " 'bagging': 0.8762117822520507,\n",
       " 'balancedRF': 0.8333333333333334,\n",
       " 'balancedbagging': 0.877703206562267,\n",
       " 'easyEnsemble': 0.8288590604026845,\n",
       " 'random': 0.8523489932885906,\n",
       " 'rusboost': 0.7026472781506339,\n",
       " 'smote': 0.8558911260253542}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "Xxpc2AxJmJPQ",
    "outputId": "e83f4833-a0a7-4391-a655-572f160ef9f7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFVCAYAAADiwegeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxcVZnu8d/DPE8SbRUCKogdEVoIk4iCioIiiCKT2jgANoKNrVfFlkZFLzbY2u2stAOKOICCogYQuaAMMhOZ0XQUBKVBZFZA4Ll/rF2kUjlDRU7Vqpz9fD+f80ntXftUvalU9rv3Gt4l20RERHstVTuAiIioK4kgIqLlkggiIlouiSAiouWSCCIiWi6JICKi5ZIIIiJaLokgpoyk30r6i6T7JP2vpOMkrdI8d46k/ZvH20uypFN6fn/TZv85Pfslab6ka/uM4SXN4zc2r/eenmNulrR98/iDkv4q6d7m51eSPiPpyV3Hby/p5jHe6zhJD3cf2/WalrRn175lmn3rjxP3OZIeaGK4R9Jlkg6TtHzP636j38+m6zXvk3S3pJ9Lek7P6/21eb7zc5ekmT37LOn+ru3tJK0j6XuS/ti89tWS3jj2v0qMuiSCmGqvtL0KsBkwGzh8nONuB7aR9ISuffsBvxrj2BcATwSeLmmLxYznT8B7JK06wTHfsb0qsBawO/B3wGW9J/huklYGXgPcDbx+nPf9kKSlFyPWQ5o4ngy8C9gbmCNJE/zOZJ/NIc2/x1rAOcDxPc9/x/YqXT9r2L6pe19z3KZd+85tXud3wHrAE4A3AP+7GH/XGCFJBDEQtm8BTgM2HueQh4DvU052NCfMvYATxjh2P+AHwJzm8eK4DvgF8M4+Yv6r7WuaOG6nnIzH8xrgLuDIcWI6nfJ3HCtJTBbH/bbPAXYFtgFeMcHhfX02th8Bvg3MWtx4xrEFcFwT68O2r7B92hS9dgxZEkEMhKR1gZcDV0xw2NeBf2wevwy4Gvh9z+usBOxBSRAnAHtLWm4xw/k34B2S1urn4Oak+QNguwkO2w/4FuXk+ixJm/e+TPO+H5C07GLG24njJuDS8eJYnM+m2f864MK/JZYxXAh8VtLekmZO0WtGJUkEMdW+L+ku4DzgZ8BR4x1o+wJgLUkbURLC18c47NXAg8BPgB8DyzLxFfJY7zMXOBN472L82u8pzSmLaE58OwDftP2/wFksSGjd73sq5c5i/8WJt9846O+z+VTz73EvcAjwoZ7n92z6BTo/Z/cZ12uBcynJ7jeS5v4NzXYxIpIIYqq9qmlnXs/222z/ZZLjj6ecoHYAThnj+f2AE5vmhweA77H4zUMARwAHSXpSn8c/ldLOP5Y3ANc1CQbK1fi+41z5Hw68H1hhcYLtM45+Ppt/tr0GsCKwC/BdSZt0PX9i8+/V+dmhn6Bs32n7MNvPBp4EzKVcBEzUnxEjapnaAUTrHQ/MA75u+8/d5xFJ6wAvAraU9Jpm90rACpLWtv3Hft/E9vWSTqaclCckaSnglcBPxznkH4GZkm5ttpehdJi+nNKk1P2+Z0qaB7yt31i74lgX2Bw4eoznFuuzsf0ocG4Ty0uBKxc3nvHY/qOk/6AkobWAO6bqtWM4kgiiKtu/kfRCYP4YT7+BMoqo9yr1AmAf4NOL+XYfopwAx7xqlbQMsCHwQcrIoU+Mccw2wDOA51KafTo+TkkQP+j9HUryGWv/mJq2/y2A/wQupnQE91rsz6aJfRZwTb+xTBDj0ZQkfj3lbuMgYJ7tJIElUJqGojrb59n+/RhP7Qd8zvat3T/AF/gbmods/4Zy8lq556m9JN1HGQp6KuWKdvMJYvqB7at6YvoksMtYHdK2z6ec0CfzGUn3UoZh/helqWen5mp+rDj6+Ww+0xn/3/zdD+8Z3bNXz5yB+yQ9sY9YV6I05d1FSeLrUUY5xRJIWZgmIqLdckcQEdFySQQRES2XRBAR0XJJBBERLZdEEBHRckvcPIK1117b66+/fu0wIiKWKJdddtkfbc8Y67klLhGsv/76XHrppbXDiIhYoki6cbzn0jQUEdFySQQRES2XRBAR0XJJBBERLZdEEBHRckkEEREtl0QQEdFySQQRES23xE0oi4hi/cN+PGWv9dt/713zPtokiSCiDznpxnSWpqGIiJZLIoiIaLkkgoiIlksfQUREBaPU75RE0HJT9WVMB2jEkmtaJoJRyrQREaMufQQRES2XRBAR0XJJBBERLTct+whiyZY+nojhSiKIiGkvo+MmlqahiIiWSyKIiGi5gSYCSTtJukHSPEmHjfH8TElnS7pC0pWSXj7IeCIiYlEDSwSSlgY+C+wMzAL2kTSr57DDgRNtPxfYG/jcoOKJiIixDfKOYEtgnu35th8Cvg3s1nOMgdWax6sDvx9gPBERMYZBjhp6KvC7ru2bga16jvkg8BNJbwdWBl4ywHgiImIMtTuL9wGOs70O8HLgeEmLxCTpQEmXSrr09ttvH3qQERHT2SATwS3Aul3b6zT7ur0FOBHA9i+AFYC1e1/I9rG2Z9uePWPGjAGFGxHRToNMBJcAG0p6mqTlKJ3Bp/YccxPwYgBJf09JBLnkj4gYooElAtsPA4cAZwDXUUYHXSPpSEm7Noe9CzhA0i+BbwFvtO1BxRQREYsaaIkJ23OAOT37juh6fC2w7SBjiIiIidXuLI6IiMqSCCIiWi6JICKi5ZIIIiJaLokgIqLlkggiIlouiSAiouWSCCIiWi6JICKi5ZIIIiJaLokgIqLlkggiIlouiSAiouWSCCIiWi6JICKi5ZIIIiJaLokgIqLlkggiIlpuoEtVRkT7rH/Yj6fkdX7776+YkteJyeWOICKi5ZIIIiJaLokgIqLlkggiIlouiSAiouWSCCIiWi6JICKi5ZIIIiJaLokgIqLlkggiIlouJSaGKFPvI2IU5Y4gIqLlkggiIlouiSAiouWSCCIiWi6JICKi5ZIIIiJaLokgIqLlkggiIlpu0kQg6RhJq0laVtJZkm6X9Pp+XlzSTpJukDRP0mHjHLOnpGslXSPpm4v7F4iIiMennzuCl9q+B9gF+C2wAfDuyX5J0tLAZ4GdgVnAPpJm9RyzIfA+YFvbzwbesVjRR0TE49ZPIuiUoXgFcJLtu/t87S2Bebbn234I+DawW88xBwCftX0ngO3b+nztiIiYIv0kgh9Juh7YHDhL0gzggT5+76nA77q2b272dXsm8ExJ50u6UNJO/QQdERFTZ9Kic7YPk3QMcLftRyT9mUWv7B/P+28IbA+sA/xc0nNs39V9kKQDgQMBZs6cOUVvHRER0F9n8cHAo7YfaXYtB7y6j9e+BVi3a3udZl+3m4FTbf/V9m+AX1ESw0JsH2t7tu3ZM2bM6OOtIyKiX/00DR3QfYXetOcf0MfvXQJsKOlpkpYD9gZO7Tnm+5S7ASStTWkqmt/Ha0dExBTpJxEsLUmdjWY00HKT/ZLth4FDgDOA64ATbV8j6UhJuzaHnQHcIela4Gzg3bbvWNy/RERE/O36WZjmdOA7kr7YbL+12Tcp23OAOT37juh6bOCdzU9ERFTQTyJ4L+Xkf1CzfSbwpYFFFBERQ9XPqKFHgc83PxERMc2MmwgknWh7T0lXAe593vYmA40sIiKGYqI7gkObP3cZRiAREVHHuInA9h+aEULH2d5hiDFFRMQQTTh8tJlE9qik1YcUT0REDFk/o4buA66SdCZwf2en7X8eWFQRETE0/SSCk5ufbot0HkdExJKpn0Swhu1Pdu+QdOh4B0dExJKlnxIT+42x741THEdERFQy0TyCfYB9gadJ6i4Wtyrwp0EHFhERwzFR09AFwB+AtYGPd+2/F7hykEFFRMTwTDSP4EbgRmAbSesBG9r+qaQVgRUpCSEiIpZw/SxMcwDwXaBTfXQdyjoCERExDfTTWXwwsC1wD4DtXwNPHGRQERExPP0kggdtP9TZkLQMmUcQETFt9JMIfibpX4EVJe0InAT8cLBhRUTEsPSTCA4DbgeuoixQMwc4fJBBRUTE8PS7MM1/Nz8RETHN9DNqaBdJV0j6k6R7JN0r6Z5hBBcREYPXT62h/wJeDVzVLDYfERHTSD99BL8Drk4SiIiYnvq5I3gPMEfSz4AHOzttf2JgUUVExND0kwj+L2VxmhWA5QYbTkREDFs/ieAptjceeCQREVFFP30EcyS9dOCRREREFf0kgoOA0yX9JcNHIyKmn34mlK06jEAiIqKOfu4IIiJiGksiiIhouSSCiIiW66fW0NaSVu3aXk3SVoMNKyIihqWfO4LPUyaUddzX7IuIiGmgn0Sg7jpDTVnqfiaiRUTEEqCfRDBf0j9LWrb5ORSYP+jAIiJiOPpJBP8EPA+4BbgZ2Ao4cJBBRUTE8PQzoew2YO8hxBIRERVMmggkfRVYZC0C228eSEQRETFU/TQN/Qj4cfNzFrAaC48iGpeknSTdIGmepMMmOO41kixpdj+vGxERU6efpqHvdW9L+hZw3mS/J2lp4LPAjpS+hUsknWr72p7jVgUOBS5ajLgjImKK/C0zizcEntjHcVsC82zPt/0Q8G1gtzGO+zBwNPDA3xBLREQ8Tv3MLL63p/z0D4H39vHaT6Wsd9xxc7Ov+7U3A9a1/ePFiDkiIqZQtTLUkpYCPgG8sY9jD6QZsjpz5sxBhBMR0Vp9zRCWtCalSWiFzj7bP5/k124B1u3aXqfZ17EqsDFwjiSAvwNOlbSr7Uu7X8j2scCxALNnz15kBFNERPzt+hk+uj+lM3cdYC6wNfAL4EWT/OolwIaSnkZJAHsD+3aetH03sHbX+5wD/J/eJBAREYPVT2fxocAWwI22dwCeC9w12S/Zfhg4BDgDuA440fY1ko6UtOvjiDkiIqZQP01DD9h+QBKSlrd9vaSN+nlx23OAOT37jhjn2O37ec2IiJha/SSCmyWtAXwfOFPSncCNgw0rIiKGpZ9RQ7s3Dz8o6WxgdeD0gUYVERFDs7gTyjayfWozQSwiIqaBxU0E/zSQKCIioprFTQQaSBQREVHN4iaCVw4kioiIqKafWkNHNaOGsH2zpDUlfWTwoUVExDD0c0ews+3HJpDZvhN4+eBCioiIYeonESwtafnOhqQVgeUnOD4iIpYg/UwoOwE4q1myEuBNwNcGF1JERAxTPxPKjpb0S+Alza4P2z5jsGFFRMSw9FWGGrgCWJayiP0VgwsnIiKGrZ9RQ3sCFwN7AHsCF0naY9CBRUTEcPRzR/B+YAvbtwFImgH8FPjuIAOLiIjh6GfU0FKdJNC4o8/fi4iIJUA/dwSnSzoD+FazvRc9awxERMSSa8JEoLKY8KcoK5Q9v9l9rO1TBh1YREQMx4SJwLYlzbH9HODkIcUUERFD1E9b/+WSthh4JBERUUU/fQRbAa+TdCNwP6UUtW1vMtDIIiJiKPpJBC8beBQREVFNPyUmslB9RMQ0lvkAEREtl0QQEdFySQQRES2XRBAR0XJJBBERLZdEEBHRckkEEREtl0QQEdFySQQRES2XRBAR0XJJBBERLZdEEBHRckkEEREtl0QQEdFySQQRES2XRBAR0XIDTQSSdpJ0g6R5kg4b4/l3SrpW0pWSzpK03iDjiYiIRQ0sEUhaGvgssDMwC9hH0qyew64AZjfrH38XOGZQ8URExNgGeUewJTDP9nzbDwHfBnbrPsD22bb/3GxeCKwzwHgiImIMg0wETwV+17V9c7NvPG8BThtgPBERMYZJF68fBkmvB2YDLxzn+QOBAwFmzpw5xMgiIqa/Qd4R3AKs27W9TrNvIZJeArwf2NX2g2O9kO1jbc+2PXvGjBkDCTYioq0GmQguATaU9DRJywF7A6d2HyDpucAXKUngtgHGEhER4xhYIrD9MHAIcAZwHXCi7WskHSlp1+awjwGrACdJmivp1HFeLiIiBmSgfQS25wBzevYd0fX4JYN8/4iImFxmFkdEtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES0XBJBRETLJRFERLRcEkFERMslEUREtFwSQUREyyURRES03EATgaSdJN0gaZ6kw8Z4fnlJ32mev0jS+oOMJyIiFjWwRCBpaeCzwM7ALGAfSbN6DnsLcKftDYD/BI4eVDwRETG2Qd4RbAnMsz3f9kPAt4Hdeo7ZDfha8/i7wIslaYAxRURED9kezAtLewA72d6/2X4DsJXtQ7qOubo55uZm+3+aY/7Y81oHAgc2mxsBN0xRmGsDf5z0qOFKTP1JTP0bxbgSU3+mMqb1bM8Y64llpugNBsr2scCxU/26ki61PXuqX/fxSEz9SUz9G8W4ElN/hhXTIJuGbgHW7dpep9k35jGSlgFWB+4YYEwREdFjkIngEmBDSU+TtBywN3BqzzGnAvs1j/cA/p8H1VYVERFjGljTkO2HJR0CnAEsDXzF9jWSjgQutX0q8GXgeEnzgD9RksUwTXlz0xRITP1JTP0bxbgSU3+GEtPAOosjImLJkJnFEREtl0QQEdFyrUoEkg7tZ19ERJu0KhGwYIRStzcOO4iIiFGyREwoe7wk7QPsCzxNUvcQ1tUoo5WqknS87TdMtm/IMc0G3g+sR/meCLDtTSrEcpztNzaP97P9tUl+ZWgkXQX0jri4G7gU+IjtKvNiJH1qjN13U0bs/WDY8QBIOsv2iyfbN+SYVgLeBcy0fYCkDYGNbP+oVkxNXOsBG9r+qaQVgWVs3zuo92tFIgAuAP5Ama798a799wJXVoloYc/u3mgK9m1eKZaOE4B3A1cBj1aOZdOux4eyoD7VKDgNeAT4ZrO9N7AScCtwHPDKOmGxAvAs4KRm+zXAb4BNJe1g+x3DCkTSCpTPZG1Ja1IuKqBciD11WHGM46vAZcA2zfYtlM+sWiKQdAClpM5awDMok3G/AAwsYbYiEdi+EbhR0kuAv9h+VNIzKf9RrqoVl6T3Af8KrCjpns5u4CHqj2m+vZnrMQpGeYzzS2xv1rV9laTLbW8m6fXVooJNgG1tPwIg6fPAucDzGf53/q3AO4CnUE66nURwD/CZIcfS6xm292paDbD95xEofHkwpWjnRQC2fy3piYN8w1Ykgi4/B7Zrrkp+Qpn9vBfwuhrB2P4o8FFJH7X9vhoxTOADkr4EnAU82Nlp++QKsazTNHWo6/FjbP9zhZg6lpa0pe2LASRtQZlACfBwvbBYE1iF0hwEsDKwlu1HJD04/q9NPdufBD4p6e22Pz3M9+7DQ03TiwEkPYOu73slD9p+qJOPmvI7A70YalsiUJPx3wJ8zvYxkubWDgr4kaSVbd/fXEVuBnyyuZOp5U2UO6ZlWdA0ZKBGInh31+NLK7z/RPYHviJpFUqiugfYX9LKwEcrxnUMMFfSOU1cLwCOauL6aaWYbpW0qu17JR1O+Z5/xPblleIB+ABwOrCupBOAbak/gORnkjotBTsCbwN+OMg3bNXMYklXUD7U/wTe0pS8uMr2cyrHdSWlHXwTSrvyl4A9bb+wYkw32N6o1vv3S9JM2zeNQByrA9i+e7Jjh0XSkylNDACX2P595XiutL2JpOcDHwE+Bhxhe6vKcT0B2JqSMC/sLYNfIZ6lKIt2vbSJ6Qzb/z3I92zbHcE7gPcBpzRJ4OnA2ZVjAnjYtiXtBnzG9pebu5aaLpA0y/a1leMAQNI2lI7Fn9u+TdImwGHAdixc5XbYcS1P6YhdH1imcztv+8haMXVZCrid8v98A0kb2P55xXgeaf58BXCs7R9L+kiNQCRt1rPrD82fM5uLi5p3KW9vmtMeO/lLOrTZNxCtuiPokLSS7T/XjqND0s8ot6dvppzYbgN+WfNORdJ1lBELv6G0mdYcPvoxYBdgLrABpZDh/pSmly/afmDYMXXFdjqlHf4yFpzosP3xcX9pCCQdTen/uoaupj3bu1aM6UeUUTk7UpqF/gJcbHvTCX9xMLFMdAFo2y8aWjA9OoMNevZdYfu5A3vPNiWC5qryy8AqtmdK2hR4q+23VY7r7yjzHC6xfa6kmcD2tr9eMab1xtpfo99C0rXAZrYfaDr6fwdsbPu3w46ll6SrbW9cO45ekm4ANrFdu+PzMc2Y/Z2Aq5qRME8GnmP7J5VDGwld852eTxnh1bEa8Mgg51u0rWnov4CX0ayLYPuXkl5QNySwfWvTUbWFpF0oV0nVkkAT041Notyu2XWu7V9WCueBzlW/7Tsl/XoUkkDjAknPsV1tGPI45lM6+kcmETQDNf4HeJmkl1G+U1WTQDPH4W2Uk68pJ+AvVLrLrDbfqW13BBfZ3qr7NkvSL2vcmvbEtSel4+wcShPMdsC7bX+3YkyHAgewYJTQ7pR23aEP/5N0F2Xob8cLurcrN3dcS2muqt6E1hPX9ygDEHqH/1YbajtK36mumE6knGi/0ezaF1jD9mtrxQQg6UnAFs3mxbZvG+j7tSwRfBf4BGUSy1aUWaqzbQ97QZzeuH4J7Nj5x5Y0A/hpzQTVjGTaxvb9zfbKwC8q9RFMOHrK9s+GFUuvUWpC6yZprLpa1CzPMUrfqa6YrrU9a7J9Q47ptcB/MMQLw7Y1Df0T8EnK6JNbKJPKDq4aUbFUT8a/g/oFAUVX52fzuMqMy5on+vFIWs32PZSryZEzSvWYuozMd6rL5ZK2tn0hgKStqD9X5XBgi94LQyCJ4PFq6vd80naVWcSTOF3SGcC3mu29gDkV44FSg+UiSac026+idLQPncYu7PaYSleU36SMZLqMElv3Cc3A0yvEhKQTbe853mdWucmq+zslYDfqf6eWpfTzdOaizASurxFTl6FfGLataeg84EW2H6odSy9Jr6Z0WEHpRDtlouOHoRlr3R3TFZXi6DS/dO7ejm/+fD2lPf6w4Uc1miQ92fYfRrjJqvOdMnDeCHynxlTzc2qGS2/CwheGV9l+z8Des2WJ4OvA31NGDd3f2W/7E9WCajSdQ1tS/oMMvHNogjjWmuh529XKdo81lnqsMddDjmms974buNF2zVpDI6kZifYCmhE6FUeiPaYZkrwuXS0klSeUIek1lHIXMIQLw9Y0DTX+p/lZCli1ciyPGWPU0Kcl1Ro11N3UMRO4s3m8BnAT8LQKMXVI0ra2z282nkf9vpTPUSZHXUn5nJ4DXA2sLumgWsMjJd3L+OskvMv2/AoxdUYNfY/yWX1DUu1RQx+m1Bb6HxZ8XgaqTSgDsP09SWfSnKMlrTXIi7BW3RF0qBQIw/Z9tWOBkR019N+UUhxzmu2dgVfZfmvFmDYHvgKs3uy6C3hzzas3SScD/2b7mmZ7FnAk8B7gZNv/UCmuDwM3U/oyRFkn4RnA5cBBtrevENMojhq6gTKpbWSaiyW9FfgQ8ABlVnhnSPLA+p1adUcgaWNK+/JazfYfgX/s/CeuaBRHDW1t+4DOhu3TJB1TMyDbl1EWVhmlAm/P7P7+2L5W0rNsz1fdsva79lxIHCtpru33qlS2rGEURw1dTbnbrdIUO47/Q5k5P7Tid61KBJTFXt5p+2wASdtTCjs9r2ZQjOaood+rlAruTLR5HVC7euWTgKOAp9jeubn63sZ2lZEnjWtUFn35drO9F3CtSjG6v9YLiz83TY6d5sU9KFeYUG+hn5EZNdTlo8AVkq5m4Yl31SYpUpqphloLrVVNQ2PNIh6FmcVNHCM1aqjpNP4ApWMPykzeD1XuLD6NcjJ5v+1NVRbsuMJ1i/OtyIISBQDnU/oNHgBWqtX8qFJZ95OUJRgNXAj8C2X+zOa2z6sU10iMGuqK5xrgi/QsyVp5kuJzaZImQ5oV3rZEcAqljbR7+OHmtnevF1WhUnhuK8qX8RLbt1YOaeRIusT2Fj0lQubWaoePxdckgu0o3/PzR2B0ziW2t5j8yOGRdDFwHosmp4FNEmxb09CbKZ0wJ7OgwNSbq0YESNofOAL4fywYNXSk7a9UjOmZlLbK9Vl4WF3N0RT3qywi0llWcGsWLMVYxTgTtzqjcz5i+47hRwXqWc6zcTdwqe0fDDseAElHAK9lwaihr0o6yXaVNQka50r6KGVIeffVd80Etaztdw7zDVtxRyDp1W7W2pW0pu07a8fUrRm58LzOSaM52V3giiuENSOZvsCidfYvqxjTZsCngY0pnXwzgD1sD7Qy4yQxHUP5fL7Z7NobWAm4FXi+7VdWiutYylKjJzW7XkMpjPcEYL7td1SI6QZgUzeVPZtmtbmVv+djrUvgmhc8ko4CfktZnrI7OWX46OPRPemo9gSksUi6gLL+wEPN9nLAObardWJLusz25rXefzxNv8BGlCvKG2zX7JAdbxGRy21vporLoEq6ENjW9iPN9jKUO+DnU2apDr2oWnPS3d32Xc32GpQhtlXH7I8aSb/p2nzsBJ3ho4+fxnlclaTO7d88ymiKH1D+4XdjwPXH+/BDSW8DTmFIVyWTkXQwcELXmP01Je1j+3O1YgKWlrSl7YubmLYAlm6eqzmzeE1gFRY0na0MrGX7EUlDXaNA0qcp3+u7KaOszmy2dwQuHmYsY8Q2iiPR3gucbvseSf9GmbD44UG+YVsSwYpNT/xSwArN48cSQsX2wM7s5s6M544qbbg9OmWM3921r1oxtcYBtj/7WDBlkZoDKKN0atkf+EozSVHAPcD+zWSpj1aM6xhgrqRzmrheABzVxPXTIcfSqeZ5GeXCouOcIccxluNoRqI1278CvkPdYa2H2z5R0vMpM5z/A/g8ZTDJQLSlaWhk1yeN/jUds5u4+dKqVJS90vaz60YGIzbJDSgF6Cj1q6CMRKs6D6Rbp75Pzf6dJo6RG4nWiaXpxL7K9jc14DWLW3FHYHuH2jFMpCkp8R7g2cAKnf21E1QzE3sWC8dUcwnN04HvSPpis/3WZl9Vkl5B82/XmU1s+8iqQRUPUJY+XAHYQNIGtn8+ye8MTHN3sivlvHMZcJuk84c9QqbHyI1EA25pvj3OsDAAAAsoSURBVOM7Akc3kxMHWmmgFYlgCXAC5XZ0F8riOfsBt9cMSNIHgO0piWAOsDNlbHPNRPBeysn/oGb7TOBL9cIBSV+gjBLaoYllDyq3e8NjQ5IPBdYB5gJbA7+gbjG11Zt27/2Br9v+QFN/qKZ3UoaOPkPS+TQj0eqGxJ7ATsB/2L6rubN79yS/87i0omlo1HVG6Ei6slOAq/ZEl6YZZlPKzN1Nm061b9jesVZMo6jzb9b15yrAaba3qxzXVZQ1by+0/Q+SngUcZfvVlWN6KfA1yuzwS7q/8xXjGqmRaDXULmwWReeL9wdJr2g6sydcF2AIHrD9KPCwpNUoRbnWrRmQpG0lnSnpV5LmS/qNpKGXU+7xl+bPP0t6CuXf8skV4+l4oGu8/vK2r6ec7Go6EjgDmNckgacDv64ZkMr6wCs2I9FeRWl6HKnh5cPQuqYhSZuw6GzZk6sFVHyk6Wx8F2XC1GqUujBVqDR0X9mM8/5vSnvufZSmhZq+TPlcFprkVtmPms/pGEpcULm5qnFzE9f3gTMl3QlUXZ3M9kksmOCGy5oIr6kXEVBKiJ/UjNB5MUMYoTOKWtU0JOkrlCXgrmFBDQ/brl5mYtR0T4aStD6w2giM8LjI9kj9B21mxx5EqZ/TKVvy+c7V+CiQ9ELKGg6nu2LdfUlfZex1lKv9/6sxQmcUte2OYOsaMyrH0zXRZkyDrDbYh8slbWH7Etu/rRhHt7NV1nM9mdGpC/M14F6gU9tnX0qH+p7VImpo4Uqf59dMAo0fdT1eAdidyqXNqTBCZxS17Y7gy8DHbV9bOxYASZ1JW9tSRud8p9l+LXCt7X+qEhgg6XpgA0pzwv0sWCWp5mpSo1gX5trei4ux9g2bFhR46zR7vgqoXeBtIZKWopSirllKZSXKCJ2rbP+6GaHzHFdaYrSWtiWCF1KGit1KuaKsfnJr4rqQUqDs4WZ7WcqaBFtXjGm9sfbbrtrOPGokfQP4jO0Lm+2tgINt/2PluEauwFsvSRsBP7a9QeU4lgaexML9hjfVi2j42tY09GXgDfTU+R4Ba1I6iDt1fFZp9lUzqif87slbnX01Jm9pQfnpZYELJN3UbK8HXD/seMbwe8pn1OmrWJ6yKE0VzQCERyiDDjpupcwNqUbS2ykLMP0vXf2GlL7E1mhbIrjd9qm1gxjDv1OWyzubBXVhPlg1ohE0YpO3dqn0vhMa1QJvtt00mW1cK4ZxHAps5ErrRoyKtjUNfY6yUHVvne/aw0dpxqC/AbiOcrL7fc1yAKNoVCdvjZKufqcxeYCrXE1G0tcozWiX1IqhV3PxtWOnWbat2nZHsCIlAby0a59Z0KFWxYiWAxhFvZO37mA0Jm+NjJon+j5sBbxO0sgMQADmA+dI+jELXxx+ol5Iw9eqRGD7TbVjGMehLCgHsEOnHEDlmEZRZ/LWxyhrT5vRmLw1MjT20pmPqXzSfVnF9x7PTc3Pcs1PK7WtaWgdyszdbZtd5wKH2r65XlQLlcKdC2xl+0FJ14xCeeVR1Yz3XmGUyj6Pgq7RXgc3fx7f/Pl6ytX3YcOPaskiaZm2NRW1LRGcSVlbtvs/x+tqF1KTdArwJuAdlOagOykLWL+8ZlyjQtKEhdJGoY9n1Iw1O1YjuExrLZLOs/385vHxtt/Q9VzrPqdWNQ0BM2x/tWv7OElDX8S7l+3dm4cfbDqvVmcE6uyPkIkWgK/exzOiJGlb2+c3G8+jhTNmJ7By1+PekUwjs5ztsLQtEdwh6fXAt5rtfSgdjiPD9s9qxzBqRrhvZ5S9hbKE5urN9l1Aamot4HEej7U97bUtEbyZ0kfwn5R/7AsoTTKxhBiVCWWjzvZlwKYawSU0R8Qaknan3CWt0dX8KModeau0qo8glmzjTSiz/ZaqgY2gZiGho4Cn2N5Z0ixgG9s1F2UfGU0l1HG17S60FYlgxKt8Rp8yoax/kk4DvkpZCWzTZhWuKzqlxaOQtLTtUVnbopq2dB5dSlk0ZAVgM8qqSL8G/oEWjx1eAo3qamCjaG3bJ9LUz2mGQ7b+hDeGX0v6WHPH1Fqt6CPozLaUdBALV/n8AmUuQSwZRnU1sFF0v6Qn0NwJS9qaUn8oFrYpsDfwpaYs9leAb9u+p25Yw9WKpqGOpjTvNrb/1GyvSZnNOzKleWN8S8JqYKOiWZTm05ShkVcDM4A9aq8yN8qaMvXfpNQj+y7wYdvz6kY1HG1LBG+iVPVcqMrniNdniYakEymrgX2j2bUvsLrt6quBjaKmX2Ajynf9Btt/rRzSyGnWIngFZfTg+pTJpidQLjaOsv3MetENT6sSAYCkv2PBwtQX2b61ZjzRv1FdDWwUSToYOMH2Xc32msA+tj9XN7LRImk+5cLwy7Yv6HnuU20ZSNLGRPBUyuIh3asRpdzzEmBUVwMbRZLm2v6Hnn2tW5R9MpJWsX3f5EdOb63oLO6QdDSwF3ANC69GlEQwwpaA1cBG0dKS5OZKr2kCyQi5RR0h6SOUEWmnU1Ym+xfb35j416aXVt0RNJ3Fm9h+cNKDY2SMt35yx6guq1mTpI9REuUXm11vBX5n+131oho9nTunZpbxLsA7gZ/b3rRyaEPVqjsCyiIUy9K1AEWMvpzo/ybvpZz8D2q2zyRDbceybPPnK4CTbN9dlldul7Ylgj8DcyWdxcKrEbWiQyjaw/ajwOebnxjfDyVdT2kaOkjSDKB1w5Hb1jQ05nquGT4a042kbSlDpTsDIzrLQj69ZlyjSNJawN22H5G0ErBa20YTtioRRLRFc5X7L5QZ2I+VlrA9UmXXR4GkjYFZLFzR9uv1Ihq+VjUNSdoQ+CiL/qPnKimmm7ttn1Y7iFEn6QPA9pRzwhxgZ+A8oFWJoC1F5zq+SmkzfZhSyvjrLJilGjGdnN0UU9tG0madn9pBjaA9gBcDtzalpzelhesRtOqOAFjR9lnN+OobKUtDXgYcUTuwiCnWmT0/u2ufKWtixwJ/sf2opIclrQbcBqxbO6hha1sieLCpMPhrSYcAtwCrVI4pYsrZ3qF2DEuIS5uKtsdS+lPuo6xc2Cqt6iyWtAVwHaW64Icpt4BH276oamARA5BlPSfXXBjuCzyd0lQ8E3jA9sVVAxuyViWCXs20+71tn1A7loiplGU9+yPp85RyMy+y/fdNcb6f2N6icmhD1YrOYkmrSXqfpM9IeqmKQ4B5QEoYx3T0vKYY3522PwRsA7SipPJi2sr2wTSTyGzfSQtrMrWlj+B44E7gF8D+wL9SJtjsbntuzcAiBqR3Wc87yLKeY/lr0zLQKc43gwUFKVujLYng6Z1FuyV9CfgDMDMrW8U01lnW82PA5ZQTXWoNLepTwCnAEyX9X0oT2uF1Qxq+VvQRSLrc9mbjbUdMZ5KWB1awnTWLxyDpWZS5BALOsn1d5ZCGri2J4BHg/s4msCKlAF2n/spqtWKLmEqSXj3R87ZPHlYsseRoRdOQ7aVrxxAxJK+c4DkDSQSxiFbcEURExPhacUcQ0UaZUBb9asU8goi2aSaU7QW8ndIX9lrK2gQRi0jTUMQ0JOlK25t0/bkKcJrt7WrHFqMndwQR01PvhLK/kgllMY70EURMT50JZcdQqmpCJpTFONI0FDENSVoROAjYjjJs9Fzg85lNH2NJIoiYhiSdCNzLghX49gVWt50ii7GIJIKIaUjStbZnTbYvAtJZHDFdXS5p686GpK2ASyvGEyMsncUR04ikqyh9AssCF0i6qdleD7i+ZmwxutI0FDGNSJpw0pjtG4cVSyw5kggiIloufQQRES2XRBAR0XJJBBERLZdEEBHRckkEEREt9/8B6Rb004JYhvgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(results_dict).plot.bar()\n",
    "plt.title(\"PIMA INDIAN DIABETS\")\n",
    "plt.ylabel('roc-auc metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5HxXMfpz7zM"
   },
   "source": [
    "# **resampling with bagging improves performance a little like balancedbagging in upper figure. this technique has additional steps to balance the training set **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiDwEWtl-vQa"
   },
   "source": [
    "# Cost-sensitive learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7ycoH-QG5n_"
   },
   "source": [
    "# now i choose balancedbagging for increesing precision with Cost-sensitive,\n",
    "# my purpose of using this approach is deactivate imbalance effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MfbnYahs1HE6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class MetaCost:\n",
    "    \"\"\"A procedure for making error-based classifiers cost-sensitive\n",
    "    Adapted from https://github.com/Treers/MetaCost/blob/master/MetaCost.py\n",
    "    .. note:: The form of the cost matrix C must be as follows:\n",
    "    +---------------+----------+----------+----------+\n",
    "    |  actual class |          |          |          |\n",
    "    +               |          |          |          |\n",
    "    |   +           | y(x)=j_1 | y(x)=j_2 | y(x)=j_3 |\n",
    "    |       +       |          |          |          |\n",
    "    |           +   |          |          |          |\n",
    "    |predicted class|          |          |          |\n",
    "    +---------------+----------+----------+----------+\n",
    "    |   h(x)=j_1    |    0     |    a     |     b    |\n",
    "    |   h(x)=j_2    |    c     |    0     |     d    |\n",
    "    |   h(x)=j_3    |    e     |    f     |     0    |\n",
    "    +---------------+----------+----------+----------+\n",
    "    | C = np.array([[0, a, b],[c, 0 , d],[e, f, 0]]) |\n",
    "    +------------------------------------------------+\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, cost_matrix, n_estimators=50, n_samples=None, p=True, q=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator :\n",
    "            An sklearn classifier\n",
    "        cost_matrix :\n",
    "            The cost matrix\n",
    "        n_estimators :\n",
    "            The number of estimators in the ensemble\n",
    "        n_samples :\n",
    "            The number of samples to train each estimator\n",
    "        p :\n",
    "            Is True if the estimator produces class probabilities. False otherwise\n",
    "        q :\n",
    "            True if all samples are to be used for each example\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.cost_matrix = cost_matrix\n",
    "        self.n_estimators = n_estimators\n",
    "        self. n_samples = n_samples\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X :\n",
    "            Training set\n",
    "        y :\n",
    "            Target\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError('S must be a DataFrame object')\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        # reset index, helps with resampling\n",
    "        X.reset_index(inplace=True, drop=True)\n",
    "        y.index = X.index\n",
    "\n",
    "        variables = list(X.columns)\n",
    "\n",
    "        # concatenate\n",
    "        S = pd.concat([X,y], axis=1)\n",
    "        S.columns = variables + ['target']\n",
    "\n",
    "        num_class = y.nunique()\n",
    "\n",
    "        if not self.n_samples:\n",
    "            self.n_samples = len(X)\n",
    "\n",
    "        S_ = {} # list of subdatasets\n",
    "        M = []  # list of models\n",
    "\n",
    "        print('resampling data and training ensemble')\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            # Let S_[i] be a resample of S with self.n examples\n",
    "            S_[i] = S.sample(n=self.n_samples, replace=True)\n",
    "\n",
    "            X = S_[i][variables].values\n",
    "            y = S_[i]['target'].values\n",
    "\n",
    "            # Let M[i] = model produced by applying L to S_[i]\n",
    "            model = clone(self.estimator)\n",
    "            M.append(model.fit(X, y))\n",
    "\n",
    "        print('Finished training ensemble')\n",
    "\n",
    "        label = []\n",
    "        S_array = S[variables].values\n",
    "        # for each observation\n",
    "        print('evaluating optimal class per observation')\n",
    "        for i in range(len(S)):\n",
    "            if self.q:\n",
    "                # consider the predictions of all models\n",
    "                M_ = M\n",
    "            else:\n",
    "                # consider the predictions of models which were not train on\n",
    "                # this particular observation\n",
    "                k_th = [k for k, v in S_.items() if i not in v.index]\n",
    "                M_ = list(np.array(M)[k_th])\n",
    "\n",
    "            if self.p:\n",
    "                P_j = [model.predict_proba(S_array[[i]]) for model in M_]\n",
    "            else:\n",
    "                P_j = []\n",
    "                vector = [0] * num_class\n",
    "                for model in M_:\n",
    "                    vector[model.predict(S_array[[i]])] = 1\n",
    "                    P_j.append(vector)\n",
    "\n",
    "            # Calculate P(j|x)\n",
    "            # the average probability of each class, when combining all models\n",
    "            P = np.array(np.mean(P_j, 0)).T\n",
    "\n",
    "            # Relabel:\n",
    "            label.append(np.argmin(self.cost_matrix.dot(P)))\n",
    "        print('Finished re-assigning labels')\n",
    "\n",
    "        # Model produced by applying L to S with relabeled y\n",
    "        print('Training model on new data')\n",
    "        X_train = S[variables].values\n",
    "        y_train = np.array(label)\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        print('Finished training model on data with new labels')\n",
    "        self.y_ = pd.Series(label)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        try:\n",
    "            probs = self.estimator.predict_proba(X)\n",
    "        except:\n",
    "            probs = None\n",
    "            print('this estimator does not support predict_proba')\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "pq-ulPOxA0K6"
   },
   "outputs": [],
   "source": [
    "balanced_bagging=BalancedBaggingClassifier(\n",
    "        base_estimator=LogisticRegression(random_state=1375),\n",
    "        n_estimators=20,\n",
    "        max_samples=1.0,  # The number of samples to draw from X to train each base estimator\n",
    "        max_features=1.0,  # The number of features to draw from X to train each base estimator\n",
    "        bootstrap=True,\n",
    "        bootstrap_features=False,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=1375,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_zXluqq-Yit",
    "outputId": "d9a7917a-9576-4399-fc68-9796aa4c66f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_matrix = np.array([[0, 1], [1, 0]])\n",
    "cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "FTUU5HEvCFJo"
   },
   "outputs": [],
   "source": [
    "metacost_ = MetaCost(estimator=balanced_bagging,\n",
    "                     cost_matrix=cost_matrix,\n",
    "                     n_estimators=50,\n",
    "                     n_samples=None,\n",
    "                     p=True,\n",
    "                     q=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "4i3EHcSTCWoK"
   },
   "outputs": [],
   "source": [
    "x_train_df=pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "h1Tl9J7OCn5i"
   },
   "outputs": [],
   "source": [
    "y_train_df=pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpdhe3qWCNXY",
    "outputId": "26d681e5-0883-4f4b-cd6f-b0337aae8369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling data and training ensemble\n",
      "Finished training ensemble\n",
      "evaluating optimal class per observation\n",
      "Finished re-assigning labels\n",
      "Training model on new data\n",
      "Finished training model on data with new labels\n"
     ]
    }
   ],
   "source": [
    "metacost_.fit(x_train_df, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3aeRPigGZBj",
    "outputId": "32973921-a13c-4f4e-9721-1795b231fed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80830493, 0.19169507],\n",
       "       [0.91297877, 0.08702123],\n",
       "       [0.96275297, 0.03724703],\n",
       "       [0.86469656, 0.13530344],\n",
       "       [0.85912318, 0.14087682],\n",
       "       [0.65776114, 0.34223886],\n",
       "       [0.92394977, 0.07605023],\n",
       "       [0.77739477, 0.22260523],\n",
       "       [0.91080197, 0.08919803],\n",
       "       [0.74377069, 0.25622931],\n",
       "       [0.07122527, 0.92877473],\n",
       "       [0.9161612 , 0.0838388 ],\n",
       "       [0.83216356, 0.16783644],\n",
       "       [0.65582819, 0.34417181],\n",
       "       [0.82943365, 0.17056635],\n",
       "       [0.56979403, 0.43020597],\n",
       "       [0.98174937, 0.01825063],\n",
       "       [0.74444482, 0.25555518],\n",
       "       [0.70494087, 0.29505913],\n",
       "       [0.7798266 , 0.2201734 ],\n",
       "       [0.75708084, 0.24291916],\n",
       "       [0.85495917, 0.14504083],\n",
       "       [0.77319752, 0.22680248],\n",
       "       [0.85925686, 0.14074314],\n",
       "       [0.31812435, 0.68187565],\n",
       "       [0.45748197, 0.54251803],\n",
       "       [0.2650615 , 0.7349385 ],\n",
       "       [0.69735397, 0.30264603],\n",
       "       [0.79303406, 0.20696594],\n",
       "       [0.42032603, 0.57967397],\n",
       "       [0.83292497, 0.16707503],\n",
       "       [0.81903471, 0.18096529],\n",
       "       [0.67047943, 0.32952057],\n",
       "       [0.88046814, 0.11953186],\n",
       "       [0.8814238 , 0.1185762 ],\n",
       "       [0.24237125, 0.75762875],\n",
       "       [0.87969027, 0.12030973],\n",
       "       [0.41959465, 0.58040535],\n",
       "       [0.24649561, 0.75350439],\n",
       "       [0.30103166, 0.69896834],\n",
       "       [0.94692937, 0.05307063],\n",
       "       [0.13561716, 0.86438284],\n",
       "       [0.33521154, 0.66478846],\n",
       "       [0.22793912, 0.77206088],\n",
       "       [0.80622945, 0.19377055],\n",
       "       [0.87374909, 0.12625091],\n",
       "       [0.79125645, 0.20874355],\n",
       "       [0.85822782, 0.14177218],\n",
       "       [0.91047245, 0.08952755],\n",
       "       [0.1330425 , 0.8669575 ],\n",
       "       [0.27905256, 0.72094744],\n",
       "       [0.35053326, 0.64946674],\n",
       "       [0.0745706 , 0.9254294 ],\n",
       "       [0.36120149, 0.63879851],\n",
       "       [0.65968551, 0.34031449],\n",
       "       [0.62538929, 0.37461071],\n",
       "       [0.85785474, 0.14214526],\n",
       "       [0.17202807, 0.82797193],\n",
       "       [0.79828113, 0.20171887],\n",
       "       [0.97182441, 0.02817559],\n",
       "       [0.91838668, 0.08161332],\n",
       "       [0.40167222, 0.59832778],\n",
       "       [0.60010988, 0.39989012],\n",
       "       [0.60299844, 0.39700156],\n",
       "       [0.26059162, 0.73940838],\n",
       "       [0.87531846, 0.12468154],\n",
       "       [0.86818889, 0.13181111],\n",
       "       [0.60216476, 0.39783524],\n",
       "       [0.66007226, 0.33992774],\n",
       "       [0.74607453, 0.25392547],\n",
       "       [0.91416822, 0.08583178],\n",
       "       [0.56746712, 0.43253288],\n",
       "       [0.82953747, 0.17046253],\n",
       "       [0.87097119, 0.12902881],\n",
       "       [0.21523509, 0.78476491],\n",
       "       [0.75604452, 0.24395548],\n",
       "       [0.1019893 , 0.8980107 ],\n",
       "       [0.56362098, 0.43637902],\n",
       "       [0.38220401, 0.61779599],\n",
       "       [0.72086324, 0.27913676],\n",
       "       [0.23075482, 0.76924518],\n",
       "       [0.67976043, 0.32023957],\n",
       "       [0.90791038, 0.09208962],\n",
       "       [0.823367  , 0.176633  ],\n",
       "       [0.61395616, 0.38604384],\n",
       "       [0.75569159, 0.24430841],\n",
       "       [0.51279863, 0.48720137],\n",
       "       [0.87933692, 0.12066308],\n",
       "       [0.75710922, 0.24289078],\n",
       "       [0.59404   , 0.40596   ],\n",
       "       [0.23486569, 0.76513431],\n",
       "       [0.89821952, 0.10178048],\n",
       "       [0.56695256, 0.43304744],\n",
       "       [0.89751754, 0.10248246],\n",
       "       [0.66806675, 0.33193325],\n",
       "       [0.09699734, 0.90300266],\n",
       "       [0.19020947, 0.80979053],\n",
       "       [0.91292759, 0.08707241],\n",
       "       [0.7639545 , 0.2360455 ],\n",
       "       [0.57377286, 0.42622714],\n",
       "       [0.51896013, 0.48103987],\n",
       "       [0.66929626, 0.33070374],\n",
       "       [0.61202418, 0.38797582],\n",
       "       [0.27411137, 0.72588863],\n",
       "       [0.78372389, 0.21627611],\n",
       "       [0.35298693, 0.64701307],\n",
       "       [0.68266149, 0.31733851],\n",
       "       [0.74678031, 0.25321969],\n",
       "       [0.32567965, 0.67432035],\n",
       "       [0.34536115, 0.65463885],\n",
       "       [0.68913031, 0.31086969],\n",
       "       [0.81002371, 0.18997629],\n",
       "       [0.6301584 , 0.3698416 ],\n",
       "       [0.61464854, 0.38535146],\n",
       "       [0.68044618, 0.31955382],\n",
       "       [0.70246509, 0.29753491],\n",
       "       [0.31442414, 0.68557586],\n",
       "       [0.45488456, 0.54511544],\n",
       "       [0.70781111, 0.29218889],\n",
       "       [0.84613952, 0.15386048],\n",
       "       [0.71872877, 0.28127123],\n",
       "       [0.86283064, 0.13716936],\n",
       "       [0.91202884, 0.08797116],\n",
       "       [0.83722537, 0.16277463],\n",
       "       [0.84695815, 0.15304185],\n",
       "       [0.88667994, 0.11332006],\n",
       "       [0.89376015, 0.10623985],\n",
       "       [0.81683478, 0.18316522],\n",
       "       [0.90748741, 0.09251259],\n",
       "       [0.75630459, 0.24369541],\n",
       "       [0.87369121, 0.12630879],\n",
       "       [0.44565052, 0.55434948],\n",
       "       [0.81755604, 0.18244396],\n",
       "       [0.02846027, 0.97153973],\n",
       "       [0.72108377, 0.27891623],\n",
       "       [0.86375877, 0.13624123],\n",
       "       [0.75523085, 0.24476915],\n",
       "       [0.9054018 , 0.0945982 ],\n",
       "       [0.63621049, 0.36378951],\n",
       "       [0.62614431, 0.37385569],\n",
       "       [0.87173639, 0.12826361],\n",
       "       [0.86196485, 0.13803515],\n",
       "       [0.88098041, 0.11901959],\n",
       "       [0.41187803, 0.58812197],\n",
       "       [0.07195296, 0.92804704],\n",
       "       [0.26161149, 0.73838851],\n",
       "       [0.64730592, 0.35269408],\n",
       "       [0.73042993, 0.26957007],\n",
       "       [0.77531765, 0.22468235],\n",
       "       [0.14028998, 0.85971002],\n",
       "       [0.1327641 , 0.8672359 ],\n",
       "       [0.83746639, 0.16253361],\n",
       "       [0.81684713, 0.18315287],\n",
       "       [0.4007576 , 0.5992424 ],\n",
       "       [0.34318831, 0.65681169],\n",
       "       [0.80095494, 0.19904506],\n",
       "       [0.17131368, 0.82868632],\n",
       "       [0.88085862, 0.11914138],\n",
       "       [0.78388745, 0.21611255],\n",
       "       [0.89119105, 0.10880895],\n",
       "       [0.50301979, 0.49698021],\n",
       "       [0.63703291, 0.36296709],\n",
       "       [0.78776626, 0.21223374],\n",
       "       [0.5990466 , 0.4009534 ],\n",
       "       [0.91126228, 0.08873772],\n",
       "       [0.79153483, 0.20846517],\n",
       "       [0.29556805, 0.70443195],\n",
       "       [0.74237666, 0.25762334],\n",
       "       [0.8438617 , 0.1561383 ],\n",
       "       [0.89376521, 0.10623479],\n",
       "       [0.65065178, 0.34934822],\n",
       "       [0.67507778, 0.32492222],\n",
       "       [0.86099301, 0.13900699],\n",
       "       [0.61566763, 0.38433237],\n",
       "       [0.25901354, 0.74098646],\n",
       "       [0.83594537, 0.16405463],\n",
       "       [0.87321116, 0.12678884],\n",
       "       [0.6009214 , 0.3990786 ],\n",
       "       [0.83779741, 0.16220259],\n",
       "       [0.83598265, 0.16401735],\n",
       "       [0.81560246, 0.18439754],\n",
       "       [0.84543352, 0.15456648],\n",
       "       [0.84167469, 0.15832531],\n",
       "       [0.69288255, 0.30711745],\n",
       "       [0.47617009, 0.52382991],\n",
       "       [0.54048059, 0.45951941],\n",
       "       [0.69275956, 0.30724044],\n",
       "       [0.85827788, 0.14172212],\n",
       "       [0.75110811, 0.24889189],\n",
       "       [0.2094291 , 0.7905709 ],\n",
       "       [0.19304453, 0.80695547],\n",
       "       [0.2288571 , 0.7711429 ],\n",
       "       [0.64990558, 0.35009442],\n",
       "       [0.28256942, 0.71743058],\n",
       "       [0.71127862, 0.28872138],\n",
       "       [0.65780643, 0.34219357],\n",
       "       [0.07513832, 0.92486168],\n",
       "       [0.60457761, 0.39542239],\n",
       "       [0.34377916, 0.65622084],\n",
       "       [0.91117702, 0.08882298],\n",
       "       [0.59839686, 0.40160314],\n",
       "       [0.90906067, 0.09093933],\n",
       "       [0.87293695, 0.12706305],\n",
       "       [0.81768843, 0.18231157],\n",
       "       [0.95325397, 0.04674603],\n",
       "       [0.72109191, 0.27890809],\n",
       "       [0.88597074, 0.11402926],\n",
       "       [0.2938075 , 0.7061925 ],\n",
       "       [0.80600909, 0.19399091],\n",
       "       [0.76475558, 0.23524442],\n",
       "       [0.37515842, 0.62484158],\n",
       "       [0.50913789, 0.49086211],\n",
       "       [0.41749581, 0.58250419],\n",
       "       [0.08624848, 0.91375152],\n",
       "       [0.44800297, 0.55199703],\n",
       "       [0.5525282 , 0.4474718 ],\n",
       "       [0.37900073, 0.62099927],\n",
       "       [0.50772777, 0.49227223],\n",
       "       [0.6960936 , 0.3039064 ],\n",
       "       [0.8641607 , 0.1358393 ],\n",
       "       [0.36913654, 0.63086346],\n",
       "       [0.78961776, 0.21038224],\n",
       "       [0.79647289, 0.20352711],\n",
       "       [0.83001319, 0.16998681],\n",
       "       [0.3510224 , 0.6489776 ],\n",
       "       [0.81823032, 0.18176968],\n",
       "       [0.60578536, 0.39421464],\n",
       "       [0.21495981, 0.78504019],\n",
       "       [0.59286488, 0.40713512],\n",
       "       [0.0636597 , 0.9363403 ],\n",
       "       [0.59544814, 0.40455186],\n",
       "       [0.25848991, 0.74151009],\n",
       "       [0.08515912, 0.91484088],\n",
       "       [0.421862  , 0.578138  ],\n",
       "       [0.04270213, 0.95729787],\n",
       "       [0.78669357, 0.21330643],\n",
       "       [0.83836572, 0.16163428],\n",
       "       [0.82526352, 0.17473648],\n",
       "       [0.2100826 , 0.7899174 ],\n",
       "       [0.37307495, 0.62692505],\n",
       "       [0.86638058, 0.13361942],\n",
       "       [0.89239941, 0.10760059],\n",
       "       [0.31658518, 0.68341482],\n",
       "       [0.78076509, 0.21923491],\n",
       "       [0.24021627, 0.75978373],\n",
       "       [0.72358136, 0.27641864],\n",
       "       [0.90113621, 0.09886379],\n",
       "       [0.09166624, 0.90833376],\n",
       "       [0.79793235, 0.20206765],\n",
       "       [0.90521935, 0.09478065],\n",
       "       [0.61239119, 0.38760881],\n",
       "       [0.83558105, 0.16441895],\n",
       "       [0.72051387, 0.27948613],\n",
       "       [0.17528373, 0.82471627],\n",
       "       [0.44494844, 0.55505156],\n",
       "       [0.8591159 , 0.1408841 ],\n",
       "       [0.988477  , 0.011523  ],\n",
       "       [0.90003272, 0.09996728],\n",
       "       [0.80172008, 0.19827992],\n",
       "       [0.61840264, 0.38159736],\n",
       "       [0.09645851, 0.90354149],\n",
       "       [0.71072259, 0.28927741],\n",
       "       [0.71865879, 0.28134121],\n",
       "       [0.82455179, 0.17544821],\n",
       "       [0.92466917, 0.07533083],\n",
       "       [0.76503877, 0.23496123],\n",
       "       [0.88738271, 0.11261729],\n",
       "       [0.8651862 , 0.1348138 ],\n",
       "       [0.74106205, 0.25893795],\n",
       "       [0.90794536, 0.09205464],\n",
       "       [0.73920858, 0.26079142],\n",
       "       [0.83134693, 0.16865307],\n",
       "       [0.6670836 , 0.3329164 ],\n",
       "       [0.51309567, 0.48690433],\n",
       "       [0.16872818, 0.83127182],\n",
       "       [0.12982014, 0.87017986],\n",
       "       [0.67569598, 0.32430402],\n",
       "       [0.82562847, 0.17437153],\n",
       "       [0.77528356, 0.22471644],\n",
       "       [0.64319136, 0.35680864],\n",
       "       [0.33828067, 0.66171933],\n",
       "       [0.85588663, 0.14411337],\n",
       "       [0.61448297, 0.38551703],\n",
       "       [0.78020231, 0.21979769],\n",
       "       [0.27110825, 0.72889175],\n",
       "       [0.2145414 , 0.7854586 ],\n",
       "       [0.72570516, 0.27429484],\n",
       "       [0.85978291, 0.14021709],\n",
       "       [0.34556728, 0.65443272],\n",
       "       [0.15586017, 0.84413983],\n",
       "       [0.48043432, 0.51956568],\n",
       "       [0.83341597, 0.16658403],\n",
       "       [0.16240976, 0.83759024],\n",
       "       [0.74940444, 0.25059556],\n",
       "       [0.72059127, 0.27940873],\n",
       "       [0.79958163, 0.20041837],\n",
       "       [0.03459583, 0.96540417],\n",
       "       [0.81581006, 0.18418994],\n",
       "       [0.91390187, 0.08609813],\n",
       "       [0.85611494, 0.14388506],\n",
       "       [0.9056231 , 0.0943769 ],\n",
       "       [0.40612221, 0.59387779],\n",
       "       [0.65819376, 0.34180624],\n",
       "       [0.12377847, 0.87622153],\n",
       "       [0.89395336, 0.10604664],\n",
       "       [0.0776082 , 0.9223918 ],\n",
       "       [0.77473426, 0.22526574],\n",
       "       [0.21498899, 0.78501101],\n",
       "       [0.55279713, 0.44720287],\n",
       "       [0.8915114 , 0.1084886 ],\n",
       "       [0.34759905, 0.65240095],\n",
       "       [0.87343714, 0.12656286],\n",
       "       [0.7349946 , 0.2650054 ],\n",
       "       [0.68242635, 0.31757365],\n",
       "       [0.13872415, 0.86127585],\n",
       "       [0.61626343, 0.38373657],\n",
       "       [0.02984322, 0.97015678],\n",
       "       [0.88718118, 0.11281882],\n",
       "       [0.40082057, 0.59917943],\n",
       "       [0.91017464, 0.08982536],\n",
       "       [0.68029488, 0.31970512],\n",
       "       [0.40379265, 0.59620735],\n",
       "       [0.60099163, 0.39900837],\n",
       "       [0.8053125 , 0.1946875 ],\n",
       "       [0.94991843, 0.05008157],\n",
       "       [0.89019984, 0.10980016],\n",
       "       [0.62704268, 0.37295732],\n",
       "       [0.57056164, 0.42943836],\n",
       "       [0.85205396, 0.14794604],\n",
       "       [0.47065745, 0.52934255],\n",
       "       [0.13640945, 0.86359055],\n",
       "       [0.6155296 , 0.3844704 ],\n",
       "       [0.72616438, 0.27383562],\n",
       "       [0.57689168, 0.42310832],\n",
       "       [0.22132423, 0.77867577],\n",
       "       [0.02611631, 0.97388369],\n",
       "       [0.82650565, 0.17349435],\n",
       "       [0.8716008 , 0.1283992 ],\n",
       "       [0.86518498, 0.13481502],\n",
       "       [0.86700336, 0.13299664],\n",
       "       [0.80130852, 0.19869148],\n",
       "       [0.78329975, 0.21670025],\n",
       "       [0.82675491, 0.17324509],\n",
       "       [0.8677357 , 0.1322643 ],\n",
       "       [0.50886482, 0.49113518],\n",
       "       [0.64617556, 0.35382444],\n",
       "       [0.72159857, 0.27840143],\n",
       "       [0.84342501, 0.15657499],\n",
       "       [0.45789851, 0.54210149],\n",
       "       [0.9302132 , 0.0697868 ],\n",
       "       [0.94639344, 0.05360656],\n",
       "       [0.48460707, 0.51539293],\n",
       "       [0.57020705, 0.42979295],\n",
       "       [0.63498757, 0.36501243],\n",
       "       [0.8089466 , 0.1910534 ],\n",
       "       [0.60221531, 0.39778469],\n",
       "       [0.4823602 , 0.5176398 ],\n",
       "       [0.89394531, 0.10605469],\n",
       "       [0.76762621, 0.23237379],\n",
       "       [0.84267727, 0.15732273],\n",
       "       [0.16487588, 0.83512412],\n",
       "       [0.88025615, 0.11974385],\n",
       "       [0.7332952 , 0.2667048 ],\n",
       "       [0.85643591, 0.14356409],\n",
       "       [0.94471704, 0.05528296],\n",
       "       [0.92254858, 0.07745142],\n",
       "       [0.1937924 , 0.8062076 ],\n",
       "       [0.9281751 , 0.0718249 ],\n",
       "       [0.79622949, 0.20377051],\n",
       "       [0.88154171, 0.11845829],\n",
       "       [0.86359333, 0.13640667],\n",
       "       [0.76965684, 0.23034316],\n",
       "       [0.16087293, 0.83912707],\n",
       "       [0.8334496 , 0.1665504 ],\n",
       "       [0.15189866, 0.84810134],\n",
       "       [0.85350181, 0.14649819],\n",
       "       [0.85614393, 0.14385607],\n",
       "       [0.76450533, 0.23549467],\n",
       "       [0.09648142, 0.90351858],\n",
       "       [0.42401142, 0.57598858],\n",
       "       [0.88726368, 0.11273632],\n",
       "       [0.20737032, 0.79262968],\n",
       "       [0.39719747, 0.60280253],\n",
       "       [0.93726522, 0.06273478],\n",
       "       [0.88513537, 0.11486463],\n",
       "       [0.88170445, 0.11829555],\n",
       "       [0.80128616, 0.19871384],\n",
       "       [0.65277841, 0.34722159],\n",
       "       [0.81596586, 0.18403414]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacost_.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4WKfhKkCOAP",
    "outputId": "1accc66c-20d0-4e4e-883e-defc2b02d1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "MetaCost roc-auc: 0.8336332283700705\n",
      "Test set\n",
      "MetaCost roc-auc: 0.8709917971662938\n"
     ]
    }
   ],
   "source": [
    "print('Train set')\n",
    "pred = metacost_.predict_proba(x_train)\n",
    "print(\n",
    "    'MetaCost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = metacost_.predict_proba(x_test)\n",
    "print(\n",
    "    'MetaCost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1TZbJHvHleK"
   },
   "source": [
    "now we impose cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVCqduKhHZ7O",
    "outputId": "4cca4dee-b77d-4d8b-9e6c-0c31f5ec59e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 10],\n",
       "       [ 5,  0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_matrix = np.array([[0, 10], [5, 0]])\n",
    "cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "Hg2wIHHPHsV6"
   },
   "outputs": [],
   "source": [
    "metacost2 = MetaCost(estimator=balanced_bagging,\n",
    "                     cost_matrix=cost_matrix,\n",
    "                     n_estimators=50,\n",
    "                     n_samples=None,\n",
    "                     p=True,\n",
    "                     q=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfzPuRLTKqkl",
    "outputId": "e4a40d40-6b6c-4969-e5a0-eb30dee4dbd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6W0KwGKNLXVv",
    "outputId": "3378a69c-d225-4f18-eb89-055f070bdbbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9c802142-f427-4e5e-817c-ae45fbe88e42\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606218</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.588910</td>\n",
       "      <td>0.228650</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.419689</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.508604</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403442</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.564767</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0.544933</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508604</td>\n",
       "      <td>0.150413</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432122</td>\n",
       "      <td>0.035262</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351816</td>\n",
       "      <td>0.277686</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866157</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.616580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.072176</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.075650</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows Ã— 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c802142-f427-4e5e-817c-ae45fbe88e42')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9c802142-f427-4e5e-817c-ae45fbe88e42 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9c802142-f427-4e5e-817c-ae45fbe88e42');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.000000  0.606218  0.540984  0.516667  0.222222  0.588910  0.228650   \n",
       "1    0.076923  0.419689  0.590164  0.300000  0.047281  0.508604  0.112948   \n",
       "2    0.000000  0.378238  0.000000  0.000000  0.000000  0.403442  0.145455   \n",
       "3    0.076923  0.564767  0.475410  0.300000  0.137116  0.544933  0.077686   \n",
       "4    0.076923  0.440415  0.540984  0.483333  0.000000  0.508604  0.150413   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "384  0.230769  0.575130  0.508197  0.000000  0.000000  0.432122  0.035262   \n",
       "385  0.000000  0.538860  0.622951  0.000000  0.000000  0.351816  0.277686   \n",
       "386  0.000000  0.554404  0.622951  0.000000  0.000000  0.866157  0.334986   \n",
       "387  0.538462  0.616580  0.000000  0.000000  0.000000  0.481836  0.072176   \n",
       "388  0.230769  0.512953  0.655738  0.183333  0.075650  0.369025  0.113499   \n",
       "\n",
       "            7  \n",
       "0    0.016667  \n",
       "1    0.050000  \n",
       "2    0.066667  \n",
       "3    0.016667  \n",
       "4    0.166667  \n",
       "..        ...  \n",
       "384  0.000000  \n",
       "385  0.100000  \n",
       "386  0.050000  \n",
       "387  0.266667  \n",
       "388  0.150000  \n",
       "\n",
       "[389 rows x 8 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfCBAnimLe3_",
    "outputId": "84f43861-6558-45fa-914e-ce27833d10c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiXc0_XYLwu9",
    "outputId": "0545674c-6918-488c-d4c0-b6f1de92d95c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "jhVuo-3AL2NN"
   },
   "outputs": [],
   "source": [
    "y_train_df=pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcnFXBlkH_ry",
    "outputId": "fd55ab43-0c97-4864-cdab-ea6fb08c693d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling data and training ensemble\n",
      "Finished training ensemble\n",
      "evaluating optimal class per observation\n",
      "Finished re-assigning labels\n",
      "Training model on new data\n",
      "Finished training model on data with new labels\n"
     ]
    }
   ],
   "source": [
    "metacost2.fit(x_train_df, y_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab9W4_L8IJqO",
    "outputId": "1ab68dc6-82dc-4e87-849b-e5e193a0c64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "MetaCost roc-auc: 0.8343829659619133\n",
      "Test set\n",
      "MetaCost roc-auc: 0.8672632363907531\n"
     ]
    }
   ],
   "source": [
    "print('Train set')\n",
    "pred = metacost2.predict_proba(x_train)\n",
    "print('MetaCost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "print('Test set')\n",
    "pred = metacost2.predict_proba(x_test)\n",
    "print('MetaCost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pima_indians_diabets_imbalanced_dataset_mehrdad_javadi_14010223.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
