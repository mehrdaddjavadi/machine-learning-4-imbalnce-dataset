# -*- coding: utf-8 -*-
"""pima_indians_diabets_imbalanced_dataset_mehrdad_javadi_14010223.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r-yYIqqaTsqbuJEJxrneQy4qWWb8KVcv
"""

!pip install --upgrade imblearn
!pip install scikit-learn==1.0 -U

from collections import Counter


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.ensemble import (
    RandomForestClassifier,
    BaggingClassifier,
    AdaBoostClassifier,
)

from sklearn.linear_model  import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler



from imblearn.under_sampling import RandomUnderSampler

from imblearn.over_sampling import SMOTE

from imblearn.ensemble import (
    BalancedBaggingClassifier,
    BalancedRandomForestClassifier,
    RUSBoostClassifier,
    EasyEnsembleClassifier,
)

path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'
pima_dataframe = pd.read_csv(path, header=None)
pima_dataframe

pima_values = pima_dataframe.values
pima_values

pima_values.shape

pima_data, pima_labels = pima_values[:,:8],pima_values[:,8]

pima_labels

pima_data.shape, pima_labels.shape

pima_labels_classes = np.unique(pima_labels)
pima_labels_classes

pima_number_classes = len(pima_labels_classes)

pima_number_classes

for label in pima_labels_classes:
    total = len(pima_labels[pima_labels==label])
    ratio = (total / float(len(pima_labels))) * 100
    print(f' the number of class {label} is {total} and the ratio of this class is {ratio} to all data')

pima_dataframe_new =pima_dataframe.sort_values(8)

pima_dataframe_new

"""we want 10 percent of "1" label in all data we have 268 numbers of "1" that is 34.8 with cross multipling we find out we need 77 of "1" label 268-x=77 give us x equal to 191 but after applying this to data the percentage of "1" was 13.3 after i use try and error to find the appropriate number of "1" label and i find 56, 268-56=212"""

pima_dataframe_new_values =pima_dataframe_new.values

pima_dataframe_new_values.shape

pima_values_adjusted = pima_dataframe_new_values[:-212,:]

pima_values_adjusted.shape

X, Y = pima_values_adjusted[:, :-1], pima_values_adjusted[:, -1]

n_rows = X.shape[0]
n_cols = X.shape[1]
classes = np.unique(Y)
n_classes = len(classes)

print('N Examples: %d' % n_rows)
print('N Inputs: %d' % n_cols)
print('N Classes: %d' % n_classes)
print('Classes: %s' % classes)

for c in classes:
    total = len(Y[Y == c])
    ratio = (total / len(Y)) * 100
    print(' - Class %s: %d (%.5f%%)' % (str(c), total, ratio))

X, Y



"""# **RESAMPLING METHODS**"""

resampling_dict = {
    
    'random': RandomUnderSampler(
        sampling_strategy='auto',
        random_state=1375,
        replacement=False,
    ),

    'smote': SMOTE(
        sampling_strategy='auto',
        random_state=1375,
        k_neighbors=5,
        n_jobs=4,
    ),
}

# ensemble methods (with or without resampling)

ensemble_dict = {

    # balanced random forests (bagging)
    'balancedRF': BalancedRandomForestClassifier(
        n_estimators=20,
        criterion='gini',
        max_depth=3,
        sampling_strategy='auto',
        n_jobs=4,
        random_state=1375,
    ),

    # bagging of Logistic regression, no resampling
    'bagging': BaggingClassifier(
        base_estimator=LogisticRegression(random_state=2909),
        n_estimators=20,
        n_jobs=4,
        random_state=1375,
    ),

    # bagging of Logistic regression, with resampling
    'balancedbagging': BalancedBaggingClassifier(
        base_estimator=LogisticRegression(random_state=1375),
        n_estimators=20,
        max_samples=1.0,  # The number of samples to draw from X to train each base estimator
        max_features=1.0,  # The number of features to draw from X to train each base estimator
        bootstrap=True,
        bootstrap_features=False,
        sampling_strategy='auto',
        n_jobs=4,
        random_state=1375,
    ),

    # boosting + undersampling
    'rusboost': RUSBoostClassifier(
        base_estimator=None,
        n_estimators=20,
        learning_rate=1.0,
        sampling_strategy='auto',
        random_state=1375,
    ),

    # bagging + boosting + under-sammpling
    'easyEnsemble': EasyEnsembleClassifier(
        n_estimators=20,
        sampling_strategy='auto',
        n_jobs=4,
        random_state=1375,
    ),
}

# function to train random forests and evaluate the performance

def run_randomForests(X_train, X_test, y_train, y_test):

    rf = RandomForestClassifier(
        n_estimators=20, random_state=1375, max_depth=2, n_jobs=4)
    rf.fit(X_train, y_train)

    print('Train set')
    pred = rf.predict_proba(X_train)
    print(
        'Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))

    print('Test set')
    pred = rf.predict_proba(X_test)
    print(
        'Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))

    return roc_auc_score(y_test, pred[:, 1])

# function to train random forests and evaluate the peadaormance

def run_adaboost(X_train, X_test, y_train, y_test):

    ada = AdaBoostClassifier(n_estimators=20, random_state=1375)
    
    ada.fit(X_train, y_train)

    print('Train set')
    pred = ada.predict_proba(X_train)
    print(
        'AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))

    print('Test set')
    pred = ada.predict_proba(X_test)
    print(
        'AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))

    return roc_auc_score(y_test, pred[:, 1])

# function to train random forests and evaluate the peensembleormance

def run_ensemble(ensemble, X_train, X_test, y_train, y_test):
    
    ensemble.fit(X_train, y_train)

    print('Train set')
    pred = ensemble.predict_proba(X_train)
    print(
        'ensembleBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))

    print('Test set')
    pred = ensemble.predict_proba(X_test)
    print(
        'ensembleBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))

    return roc_auc_score(y_test, pred[:, 1])

x_train, x_test, y_train, y_test = train_test_split(
    X,  
    Y, 
    test_size=0.3,
    random_state=1375)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

results_dict = {}
# we set variables in the same scale
scaler = MinMaxScaler().fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)
    
# train model and store result
roc = run_randomForests(x_train, x_test, y_train, y_test)
results_dict["Random Forest"] = roc
print()
# train model and store result
roc = run_adaboost(x_train, x_test, y_train, y_test)
results_dict["adaboost"] = roc
print()

for sampler in resampling_dict.keys():
        
        print(sampler)
        
        # resample
        x_resampled, y_resampled = resampling_dict[sampler].fit_resample(x_train, y_train)
        
        # train model and store result
        roc = run_randomForests(x_resampled, x_test, y_resampled, y_test)
        results_dict[sampler] = roc
        print()
    
        for ensemble in ensemble_dict.keys():
        
          print(ensemble)
          
          # train model and store result
          roc = run_ensemble(ensemble_dict[ensemble], x_train, x_test, y_train, y_test)
          results_dict[ensemble] = roc
          print()

results_dict

pd.Series(results_dict).plot.bar()
plt.title("PIMA INDIAN DIABETS")
plt.ylabel('roc-auc metrics')
plt.show()

"""# **resampling with bagging improves performance a little like balancedbagging in upper figure. this technique has additional steps to balance the training set **

# Cost-sensitive learning

# now i choose balancedbagging for increesing precision with Cost-sensitive,
# my purpose of using this approach is deactivate imbalance effect
"""

import numpy as np
import pandas as pd

from sklearn.base import clone


class MetaCost:
    """A procedure for making error-based classifiers cost-sensitive
    Adapted from https://github.com/Treers/MetaCost/blob/master/MetaCost.py
    .. note:: The form of the cost matrix C must be as follows:
    +---------------+----------+----------+----------+
    |  actual class |          |          |          |
    +               |          |          |          |
    |   +           | y(x)=j_1 | y(x)=j_2 | y(x)=j_3 |
    |       +       |          |          |          |
    |           +   |          |          |          |
    |predicted class|          |          |          |
    +---------------+----------+----------+----------+
    |   h(x)=j_1    |    0     |    a     |     b    |
    |   h(x)=j_2    |    c     |    0     |     d    |
    |   h(x)=j_3    |    e     |    f     |     0    |
    +---------------+----------+----------+----------+
    | C = np.array([[0, a, b],[c, 0 , d],[e, f, 0]]) |
    +------------------------------------------------+
    """

    def __init__(self, estimator, cost_matrix, n_estimators=50, n_samples=None, p=True, q=True):
        """
        Parameters
        ----------
        estimator :
            An sklearn classifier
        cost_matrix :
            The cost matrix
        n_estimators :
            The number of estimators in the ensemble
        n_samples :
            The number of samples to train each estimator
        p :
            Is True if the estimator produces class probabilities. False otherwise
        q :
            True if all samples are to be used for each example
        """

        self.estimator = estimator
        self.cost_matrix = cost_matrix
        self.n_estimators = n_estimators
        self. n_samples = n_samples
        self.p = p
        self.q = q

    def fit(self, X, y):
        """
        Parameters
        ----------
        X :
            Training set
        y :
            Target
        """

        if not isinstance(X, pd.DataFrame):
            raise ValueError('S must be a DataFrame object')

        X = X.copy()

        # reset index, helps with resampling
        X.reset_index(inplace=True, drop=True)
        y.index = X.index

        variables = list(X.columns)

        # concatenate
        S = pd.concat([X,y], axis=1)
        S.columns = variables + ['target']

        num_class = y.nunique()

        if not self.n_samples:
            self.n_samples = len(X)

        S_ = {} # list of subdatasets
        M = []  # list of models

        print('resampling data and training ensemble')
        for i in range(self.n_estimators):

            # Let S_[i] be a resample of S with self.n examples
            S_[i] = S.sample(n=self.n_samples, replace=True)

            X = S_[i][variables].values
            y = S_[i]['target'].values

            # Let M[i] = model produced by applying L to S_[i]
            model = clone(self.estimator)
            M.append(model.fit(X, y))

        print('Finished training ensemble')

        label = []
        S_array = S[variables].values
        # for each observation
        print('evaluating optimal class per observation')
        for i in range(len(S)):
            if self.q:
                # consider the predictions of all models
                M_ = M
            else:
                # consider the predictions of models which were not train on
                # this particular observation
                k_th = [k for k, v in S_.items() if i not in v.index]
                M_ = list(np.array(M)[k_th])

            if self.p:
                P_j = [model.predict_proba(S_array[[i]]) for model in M_]
            else:
                P_j = []
                vector = [0] * num_class
                for model in M_:
                    vector[model.predict(S_array[[i]])] = 1
                    P_j.append(vector)

            # Calculate P(j|x)
            # the average probability of each class, when combining all models
            P = np.array(np.mean(P_j, 0)).T

            # Relabel:
            label.append(np.argmin(self.cost_matrix.dot(P)))
        print('Finished re-assigning labels')

        # Model produced by applying L to S with relabeled y
        print('Training model on new data')
        X_train = S[variables].values
        y_train = np.array(label)
        self.estimator.fit(X_train, y_train)
        print('Finished training model on data with new labels')
        self.y_ = pd.Series(label)

    def predict(self, X):
        return self.estimator.predict(X)

    def predict_proba(self, X):
        try:
            probs = self.estimator.predict_proba(X)
        except:
            probs = None
            print('this estimator does not support predict_proba')
        return probs

balanced_bagging=BalancedBaggingClassifier(
        base_estimator=LogisticRegression(random_state=1375),
        n_estimators=20,
        max_samples=1.0,  # The number of samples to draw from X to train each base estimator
        max_features=1.0,  # The number of features to draw from X to train each base estimator
        bootstrap=True,
        bootstrap_features=False,
        sampling_strategy='auto',
        n_jobs=4,
        random_state=1375,
    )

cost_matrix = np.array([[0, 1], [1, 0]])
cost_matrix

metacost_ = MetaCost(estimator=balanced_bagging,
                     cost_matrix=cost_matrix,
                     n_estimators=50,
                     n_samples=None,
                     p=True,
                     q=True)

x_train_df=pd.DataFrame(x_train)

y_train_df=pd.DataFrame(y_train)

metacost_.fit(x_train_df, y_train_df)

metacost_.predict_proba(x_train)

print('Train set')
pred = metacost_.predict_proba(x_train)
print(
    'MetaCost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))

print('Test set')
pred = metacost_.predict_proba(x_test)
print(
    'MetaCost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))

"""now we impose cost matrix"""

cost_matrix = np.array([[0, 10], [5, 0]])
cost_matrix

metacost2 = MetaCost(estimator=balanced_bagging,
                     cost_matrix=cost_matrix,
                     n_estimators=50,
                     n_samples=None,
                     p=True,
                     q=True)

np.unique(y_train)

x_train_df

y_train.shape

np.unique(y_train)

y_train_df=pd.DataFrame(y_train)

metacost2.fit(x_train_df, y_train_df)

print('Train set')
pred = metacost2.predict_proba(x_train)
print('MetaCost roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))

print('Test set')
pred = metacost2.predict_proba(x_test)
print('MetaCost roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))